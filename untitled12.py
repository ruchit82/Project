# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MdY6gYPnVec23hU9TjQlKZd3ixAExiEy
"""

# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Title of the application
st.title("Monthly Sales Data Analysis Application")

# File uploader for data
uploaded_file = st.file_uploader("Upload your data file (Excel/CSV)", type=["xlsx", "csv", "xls"])

if uploaded_file:
    try:
        # Read uploaded file
        if uploaded_file.name.endswith('.csv'):
            data = pd.read_csv(uploaded_file)
        else:
            data = pd.read_excel(uploaded_file)

        st.write("### Preview of Uploaded Dataset:")
        st.dataframe(data.head(10))

        # Check for required columns
        required_columns = ['DocDate', 'type', 'parName', 'CATEGORY', 'weight', 'noPcs']
        if not all(col in data.columns for col in required_columns):
            st.error(f"Dataset must contain these columns: {required_columns}")
        else:
            # Handle missing values
            if data.isnull().sum().any():
                st.warning("Dataset contains missing values. These will be dropped.")
                data = data.dropna()

            # Convert DocDate to datetime
            data['DocDate'] = pd.to_datetime(data['DocDate'], errors='coerce')
            data = data.dropna(subset=['DocDate'])  # Drop invalid dates
            
            # Filter excluded categories
            excluded_categories = ['ST', 'LOOSE PCS', 'PARA BIDS', 'Langadi', 'PROCESS LOSS',
                                   'SCRAP PCC', 'BALL CHAIN', 'SIGNING TAR', 'Fine']
            df = data[~data['CATEGORY'].isin(excluded_categories)]

            # Date range filter
            st.write("### Filter by Date Range")
            min_date, max_date = df['DocDate'].min(), df['DocDate'].max()
            date_range = st.date_input("Select Date Range", [min_date, max_date], min_value=min_date, max_value=max_date)
            filtered_df = df[(df['DocDate'] >= pd.to_datetime(date_range[0])) & 
                             (df['DocDate'] <= pd.to_datetime(date_range[1]))]

            # Aggregated Summary
            st.write("### Overall Sales Summary")
            total_weight = filtered_df['weight'].sum()
            total_pieces = filtered_df['noPcs'].sum()
            st.write(f"**Total Weight:** {total_weight:.2f}")
            st.write(f"**Total Pieces:** {int(total_pieces)}")

            # Party-wise Analysis
            st.write("### Party-wise Weight Analysis")
            party_weight_summary = filtered_df.groupby('parName')['weight'].sum().reset_index()
            top_10_parties = party_weight_summary.sort_values(by='weight', ascending=False).head(10)
            st.bar_chart(top_10_parties.set_index('parName')['weight'])

            # Rank of Selected Party
            st.write("### Check Rank of a Party")
            party_name = st.selectbox("Select a Party:", options=party_weight_summary['parName'].unique())
            if party_name:
                party_rank = party_weight_summary.sort_values(by='weight', ascending=False)
                party_rank['Rank'] = party_rank['weight'].rank(ascending=False, method='dense')
                selected_party = party_rank[party_rank['parName'] == party_name]
                st.write(f"**Party Name:** {party_name}")
                st.write(f"**Rank:** {int(selected_party['Rank'].values[0])}")
                st.write(f"**Total Weight:** {selected_party['weight'].values[0]:.2f}")

            # Category-wise Analysis
            st.write("### Top Categories by Weight")
            category_summary = filtered_df.groupby('CATEGORY')['weight'].sum().reset_index()
            category_summary_sorted = category_summary.sort_values(by='weight', ascending=False).head(10)
            st.bar_chart(category_summary_sorted.set_index('CATEGORY')['weight'])

            # Weight Over Time
            st.write("### Total Weight Over Time")
            weight_over_time = filtered_df.groupby('DocDate')['weight'].sum().reset_index()
            st.line_chart(weight_over_time.set_index('DocDate')['weight'])

            # Download Filtered Data
            st.write("### Download Filtered Dataset")
            csv = filtered_df.to_csv(index=False)
            st.download_button("Download CSV", csv, "filtered_data.csv", "text/csv")

    except Exception as e:
        st.error(f"Error processing file: {e}")
else:
    st.info("Please upload a valid Excel/CSV file.")

